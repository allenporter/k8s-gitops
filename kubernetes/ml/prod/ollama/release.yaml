---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
spec:
  releaseName: ollama
  chart:
    spec:
      chart: ollama
      interval: 30m
      sourceRef:
        kind: HelmRepository
        name: ollama-helm
        namespace: flux-system
      version: 1.26.0
  interval: 5m
  # Large timeout for allowing more time for model downloads
  timeout: 15m
  install:
    remediation:
      retries: 3
  test:
    # Fix problem where helm fails to uninstall
    enable: false
  values:
    image:
      repository: ollama/ollama
      tag: 0.10.1
      pullPolicy: IfNotPresent
    ollama:
      gpu:
        enabled: true
        type: nvidia
        number: 1
      models:
        pull:
        - llama3.1  # 8b
        - llama3.2:3b
        - qwen2.5:0.5b
        - qwen2.5:7b
        - qwen3:0.6b
        - qwen3:1.7b
        - qwen3:4b
        - qwen3:8b
        - PetrosStav/gemma3-tools:4b
    extraEnv:
    - name: OLLAMA_DEBUG
      value: "1"
    # Requirements for nvidia runtime and hardware
    runtimeClassName: nvidia
    resources:
      limits:
        nvidia.com/gpu: 1

    ingress:
      enabled: true
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt
      hosts:
      - host: ollama.${name_service_dns_domain}
        paths:
        - path: /
          pathType: Prefix
      tls:
      - secretName: ollama-tls
        hosts:
        - ollama.${name_service_dns_domain}

    persistentVolume:
      enabled: true
      storageClass: "local-hostpath"
      accessMode: ReadWriteOnce
      size: 65Gi
