---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
spec:
  releaseName: ollama
  chart:
    spec:
      chart: ollama
      interval: 30m
      sourceRef:
        kind: HelmRepository
        name: ollama-helm
        namespace: flux-system
      version: 0.46.0
  interval: 5m
  # Large timeout for allowing more time for model downloads
  timeout: 15m
  install:
    remediation:
      retries: 3
  test:
    # Fix problem where helm fails to uninstall
    enable: false
  values:
    image:
      repository: ollama/ollama
      tag: 0.5.12
      pullPolicy: IfNotPresent
    ollama:
      gpu:
        enabled: true
        type: nvidia
        number: 1
      models:
      - llama3.1  # 8b
      - llama3.2:3b
      - qwen2.5:7b
      - gemma2:9b
      - llama3.2-vision:11b
      # - mistral  # 7b
      # - fixt/home-3b-v3:latest  # 3b
      # - llama3-groq-tool-use
      # - allenporter/xlam:1b
      # - allenporter/xlam:7b
    extraEnv:
    - name: OLLAMA_DEBUG
      value: "1"
    # Requirements for nvidia runtime and hardware
    runtimeClassName: nvidia
    resources:
      limits:
        nvidia.com/gpu: 1

    ingress:
      enabled: true
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt
      hosts:
      - host: ollama.${name_service_dns_domain}
        paths:
        - path: /
          pathType: Prefix
      tls:
      - secretName: ollama-tls
        hosts:
        - ollama.${name_service_dns_domain}

    persistentVolume:
      enabled: true
      storageClass: "local-hostpath"
      accessMode: ReadWriteOnce
      size: 40Gi
