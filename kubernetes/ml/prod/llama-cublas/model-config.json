{
  "host": "0.0.0.0",
  "port": 8080,
  "models": [
    {
      "model": "/data/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf",
      "model_alias": "mistral-7b-instruct-v1",
      "chat_format": "llama-2",
      "n_gpu_layers": 35,
      "offload_kqv": true,
      "n_ctx": 4096,
      "use_mlock": false
    },
    {
      "model": "/data/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf",
      "model_alias": "mistral-7b-instruct-v2",
      "chat_format": "llama-2",
      "n_gpu_layers": 35,
      "offload_kqv": true,
      "n_ctx": 4096,
      "use_mlock": false
    },
    {
      "model": "/data/models/Mistral-7B-Instruct-v0.3.Q3_K_M.gguf",
      "model_alias": "mistral-7b-instruct-v3",
      "chat_format": "llama-2",
      "n_gpu_layers": 35,
      "offload_kqv": true,
      "n_ctx": 4096,
      "use_mlock": false
    },
    {
      "model": "/data/models/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf",
      "model_alias": "llama-3-8b-instruct",
      "chat_format": "llama-3",
      "n_gpu_layers": 35,
      "offload_kqv": true,
      "n_ctx": 8192,
      "use_mlock": false
    },
    {
      "model": "/data/models/functionary-7b-v1.4/functionary-7b-v1.4.q4_0.gguf",
      "model_alias": "functionary-7b-v1.4",
      "chat_format": "functionary-v1",
      "hf_pretrained_model_name_or_path": "/data/models/functionary-7b-v1.4/",
      "n_gpu_layers": 32,
      "offload_kqv": true,
      "n_ctx": 4096,
      "use_mlock": false
    }
  ]
}
