---
clusterName: k8s-cluster
talosVersion: v1.8.4
kubernetesVersion: v1.30.7
endpoint: https://10.10.101.1:6443
allowSchedulingOnMasters: true
allowSchedulingOnControlPlanes: true
nodes:
  - hostname: kapi01
    ipAddress: 10.10.100.1
    controlPlane: true
    installDisk: /dev/sda
    # /dev/sda
    # /dev/nvme0n1
  - hostname: kapi02
    ipAddress: 10.10.100.2
    controlPlane: true
    installDisk: /dev/sda
    # /dev/sda
    # /dev/nvme0n1
    nodeAnnotations:
      accelerator: intel
  - hostname: kapi03
    ipAddress: 10.10.100.3
    controlPlane: true
    installDisk: /dev/sda
    # /dev/sda
    # /dev/nvme0n1
    nodeAnnotations:
      accelerator: intel
  - hostname: kube01
    ipAddress: 10.10.100.4
    controlPlane: false
    installDisk: /dev/sdb
    nodeAnnotations:
      accelerator: nvidia
    # NVidia extensions for older hardware that uses older proprietary drivers
    kernelModules:
      - name: nvidia
      - name: nvidia_uvm
      - name: nvidia_drm
      - name: nvidia_modeset
      # Image using these extensions
      # customization:
      # systemExtensions:
      #     officialExtensions:
      #         - siderolabs/nonfree-kmod-nvidia-production
      #         - siderolabs/nvidia-container-toolkit-production
    patches:
      - |-
        machine:
          install:
            # For 1.8.3:
            #   nonfree-kmod-nvidia 550.90.07-v1.8.3
            #   nvidia-container-toolkit 550.90.07-v1.16.1
            # image: factory.talos.dev/installer/26124abcbd408be693df9fe852c80ef1e6cc178e34d7d7d8430a28d1130b4227:v1.8.3
            # For 1.8.4:
            #   nonfree-kmod-nvidia 550.90.07-x
            #   nvidia-container-toolkit 550.90.07-x
            image: factory.talos.dev/installer/26124abcbd408be693df9fe852c80ef1e6cc178e34d7d7d8430a28d1130b4227:v1.8.4
      - |-
        - op: add
          path: /machine/sysctls
          value:
            net.core.bpf_jit_harden: 1
      - |-
        - op: add
          path: /machine/files
          value:
            - content: |
                [plugins]
                  [plugins."io.containerd.grpc.v1.cri"]
                    [plugins."io.containerd.grpc.v1.cri".containerd]
                      default_runtime_name = "nvidia"
              path: /etc/cri/conf.d/20-customization.part
              op: create


cniConfig:
  name: none
controlPlane:
  networkInterfaces:
    - interface: eth0
      dhcp: true
      vip:
        ip: 10.10.101.1
  nodeAnnotations:
    accelerator: intel
  schematic:
    customization:
      extraKernelArgs:
        - net.ifnames=0
        - i915.force_probe=7d55
      # All control plane nodes have the same intel extensions
      systemExtensions:
        officialExtensions:
          - siderolabs/intel-ucode
          - siderolabs/intel-ice-firmware
          # Note: Renamed in new version
          - siderolabs/i915-ucode

worker:
  networkInterfaces:
    - interface: eth0
      dhcp: true
  schematic:
    customization:
      extraKernelArgs:
        - net.ifnames=0

patches:
  - |-
     cluster:
       proxy:
         disabled: true
